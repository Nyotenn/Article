# NAS

> 以下是一些神经架构搜索的论文：
>
> 1. [**A Comprehensive Survey of Neural Architecture Search: Challenges and Solutions**](https://zhuanlan.zhihu.com/p/146138419)[1](https://zhuanlan.zhihu.com/p/146138419): 这篇论文是一篇综述性的文章，介绍了神经架构搜索的挑战和解决方案。它涵盖了NAS的基本概念、搜索空间、搜索策略、评估方法等方面，并对NAS的未来发展进行了展望。
> 2. [**Efficient Neural Architecture Search via Parameter Sharing**](https://zhuanlan.zhihu.com/p/356282001)[2](https://zhuanlan.zhihu.com/p/356282001): 这篇论文提出了一种高效的神经架构搜索方法，通过参数共享来减少搜索空间，从而加速搜索过程。该方法在多个数据集上进行了测试，结果表明它可以在保持性能的同时大大减少搜索时间。
> 3. [**DARTS: Differentiable Architecture Search**](https://blog.csdn.net/weixin_47196664/article/details/107075616)[3](https://blog.csdn.net/weixin_47196664/article/details/107075616): 这篇论文提出了一种可微分的神经架构搜索方法，通过梯度下降来优化网络结构。该方法在多个数据集上进行了测试，结果表明它可以在保持性能的同时大大减少搜索时间。
> 4. [**ProxylessNAS: Direct Neural Architecture Search on Target Task and Hardware**](https://cloud.tencent.com/developer/article/1656900)[4](https://cloud.tencent.com/developer/article/1656900): 这篇论文提出了一种直接在目标任务和硬件上进行神经架构搜索的方法。该方法不需要预先定义搜索空间，可以直接在目标设备上进行搜索，并且可以生成高度优化的网络结构。
> 5. [**FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search**](https://zhuanlan.zhihu.com/p/527872448)[5](https://zhuanlan.zhihu.com/p/527872448): 这篇论文提出了一种硬件感知的神经架构搜索方法，可以根据目标设备的特性来生成高效的卷积神经网络。该方法在多个数据集上进行了测试，并且在移动设备上取得了很好的性能。